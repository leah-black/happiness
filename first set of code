import cv2
import numpy as np
import pandas as pd
import time
from datetime import datetime
import mediapipe as mp
import os

def get_happiness_color(score):
    """Convert happiness score to color (BGR format)"""
    if score > 0:
        return (0, 255, 255)  # Yellow in BGR
    return (255, 0, 0)  # Blue in BGR

def add_overlay(frame, score, timestamp, tree_count, ages):
    """Add overlays to frame"""
    # Get frame dimensions
    height, width = frame.shape[:2]
    
    # Create text lines for bottom right
    timestamp_text = f"Time: {timestamp}"
    score_text = f"Happiness: {score:.2f}"
    
    # Get text size for bottom right
    font = cv2.FONT_HERSHEY_SIMPLEX
    time_font_scale = 0.7
    score_font_scale = 1.2
    thickness = 2
    line_spacing = 10
    
    # Calculate text sizes for bottom right
    (time_width, time_height), _ = cv2.getTextSize(timestamp_text, font, time_font_scale, thickness)
    (score_width, score_height), _ = cv2.getTextSize(score_text, font, score_font_scale, thickness)
    
    # Find the widest text for bottom right
    max_width = max(time_width, score_width)
    
    # Calculate position for bottom right
    padding = 20
    x_right = width - max_width - padding
    y_right = height - padding
    
    # Calculate total height needed for bottom right
    total_height = time_height + score_height + line_spacing
    
    # Add semi-transparent background for bottom right
    overlay = frame.copy()
    cv2.rectangle(overlay, 
                 (x_right - 10, y_right - total_height - 10),
                 (x_right + max_width + 10, y_right + 10),
                 (0, 0, 0), -1)
    cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
    
    # Add text lines for bottom right
    cv2.putText(frame, timestamp_text, (x_right, y_right - total_height + time_height), 
                font, time_font_scale, (255, 255, 255), thickness)
    
    cv2.putText(frame, score_text, 
                (x_right, y_right),
                font, score_font_scale, (255, 255, 255), thickness)
    
    # Add tree counter to bottom left
    tree_text = f"Trees: {tree_count}"
    cv2.putText(frame, tree_text, (padding, height - padding), 
                font, score_font_scale, (0, 255, 0), thickness)
    
    # Add age estimates if any faces detected
    if ages:
        age_text = "Ages: " + ", ".join(map(str, ages))
        cv2.putText(frame, age_text, (padding, height - padding - 40), 
                    font, time_font_scale, (255, 255, 255), thickness)
    
    return frame

def detect_faces_and_trees(frame, face_mesh):
    """Detect faces and trees in the frame"""
    # Convert the BGR image to RGB
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # Process the frame for face detection
    results = face_mesh.process(rgb_frame)
    
    # Initialize counters
    face_count = 0
    ages = []
    smiling_faces = 0
    
    # If faces are detected
    if results.multi_face_landmarks:
        face_count = len(results.multi_face_landmarks)
        
        # Simple age estimation based on face landmarks
        for face_landmarks in results.multi_face_landmarks:
            # Get face height (distance between chin and forehead)
            chin = face_landmarks.landmark[152]
            forehead = face_landmarks.landmark[10]
            face_height = abs(chin.y - forehead.y)
            
            # Very simple age estimation
            estimated_age = int(20 + (face_height * 100))
            ages.append(estimated_age)
            
            # Simple smile detection (using mouth corners)
            left_mouth = face_landmarks.landmark[61]
            right_mouth = face_landmarks.landmark[291]
            mouth_width = abs(right_mouth.x - left_mouth.x)
            
            # If mouth is wide enough, consider it a smile
            if mouth_width > 0.3:  # Adjust threshold as needed
                smiling_faces += 1
    
    # Simple tree detection
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    lower_green = np.array([35, 50, 50])
    upper_green = np.array([85, 255, 255])
    mask = cv2.inRange(hsv, lower_green, upper_green)
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    tree_count = sum(1 for c in contours if cv2.contourArea(c) > 1000)  # Adjust threshold as needed
    
    return frame, face_count, tree_count, ages, smiling_faces

def generate_report(data, output_dir):
    """Generate CSV report with collected data"""
    # Create DataFrame
    df = pd.DataFrame(data)
    
    # Calculate statistics
    stats = {
        'Total Frames': len(data),
        'Total Faces Detected': sum(d['face_count'] for d in data),
        'Total Trees Detected': sum(d['tree_count'] for d in data),
        'Total Smiling Faces': sum(d['smiling_faces'] for d in data),
        'Average Age': np.mean([age for d in data for age in d['ages']]) if any(d['ages'] for d in data) else 0,
        'Age Distribution': pd.Series([age for d in data for age in d['ages']]).value_counts().to_dict(),
        'Average Happiness Score': np.mean([d['happiness_score'] for d in data]),
        'Max Happiness Score': max(d['happiness_score'] for d in data),
        'Min Happiness Score': min(d['happiness_score'] for d in data)
    }
    
    # Save detailed data
    detailed_data = []
    for d in data:
        for age in d['ages']:
            detailed_data.append({
                'Timestamp': d['timestamp'],
                'Age': age,
                'Happiness Score': d['happiness_score'],
                'Tree Count': d['tree_count'],
                'Face Count': d['face_count'],
                'Smiling Faces': d['smiling_faces']
            })
    
    detailed_df = pd.DataFrame(detailed_data)
    
    # Save reports
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    stats_path = os.path.join(output_dir, f'video_stats_{timestamp}.csv')
    detailed_path = os.path.join(output_dir, f'video_detailed_data_{timestamp}.csv')
    
    # Save statistics
    pd.DataFrame([stats]).to_csv(stats_path, index=False)
    detailed_df.to_csv(detailed_path, index=False)
    
    print(f"\nReports generated:")
    print(f"1. Statistics: {stats_path}")
    print(f"2. Detailed Data: {detailed_path}")
    
    return stats_path, detailed_path

def main():
    # Initialize MediaPipe Face Mesh
    mp_face_mesh = mp.solutions.face_mesh
    face_mesh = mp_face_mesh.FaceMesh(
        static_image_mode=False,
        max_num_faces=10,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    
    # Load happiness data
    df = pd.read_csv('happiness_timeline_y_onesecond.csv')
    print(f"Playing happiness timeline from: happiness_timeline_y_onesecond.csv")
    
    # Open video
    cap = cv2.VideoCapture('analyzed_y.mp4')
    if not cap.isOpened():
        print("Error: Could not open video")
        return
    
    # Get video properties
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # Create output directory if it doesn't exist
    output_dir = 'processed_videos'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Create output video writer
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_path = os.path.join(output_dir, f'processed_video_{timestamp}.mp4')
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    print(f"Saving processed video to: {output_path}")
    
    # Initialize data collection
    collected_data = []
    
    start_time = time.time()
    frame_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        # Calculate current time
        current_time = time.time() - start_time
        timestamp = datetime.fromtimestamp(current_time).strftime('%H:%M:%S')
        
        # Detect faces and trees
        frame, face_count, tree_count, ages, smiling_faces = detect_faces_and_trees(frame, face_mesh)
        
        # Get happiness score for current frame
        if frame_count < len(df):
            base_score = df.iloc[frame_count]['Happiness Score']
            # Add 0.5 to the score for each face detected
            score = base_score + (face_count * 0.5)
        else:
            score = face_count * 0.5  # Just use face-based score if no base score
        
        # Collect data
        collected_data.append({
            'timestamp': timestamp,
            'face_count': face_count,
            'tree_count': tree_count,
            'ages': ages,
            'smiling_faces': smiling_faces,
            'happiness_score': score
        })
            
        # Add overlays
        frame = add_overlay(frame, score, timestamp, tree_count, ages)
        
        # Write frame to output video
        out.write(frame)
        
        # Display frame
        cv2.imshow('Happiness Player', frame)
        
        # Handle exit
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
            
        frame_count += 1
    
    # Generate reports
    stats_path, detailed_path = generate_report(collected_data, output_dir)
    
    # Cleanup
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    face_mesh.close()
    
    print(f"Video processing complete. Saved to: {output_path}")

if __name__ == "__main__":
    main()
